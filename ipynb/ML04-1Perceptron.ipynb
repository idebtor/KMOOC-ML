{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파이썬으로 배우는 기계학습\n",
    "# Machine Learning with Python\n",
    "**************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제 4-1 강: 퍼셉트론$^{Perceptron}$ \n",
    "\n",
    "## 학습 목표\n",
    "    - 퍼셉트론의 구조와 학습방법을 이해한다. \n",
    "\n",
    "## 학습 내용\n",
    "\n",
    "    - 퍼셉트론의 역사와 구조\n",
    "    - 퍼셉트론의 이진분류\n",
    "    - 퍼셉트론의 학습방법\n",
    "    - 과대적합과 과소적합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 퍼셉트론 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인공 신경망을 구성하는 기본 단위는 인공 뉴론입니다. 여러 인공 뉴론들을 체계적으로 연결하여 인공 신경망을 구성합니다. 인공 신경망의 각 인공 뉴론을 전산 과학에서는 노드$^{node}$ 혹은 간단히 뉴론이라고 하며, __퍼셉트론__이라 부르기도 합니다. 퍼셉트론은 인공 신경망의 한 종류로 인식되며, 1957년에 코넬 항공 연구소의 프랑크 로젠블라트$^{Frank \\ Rosenblatt}$가 고안한 알고리즘입니다. 그가 발표한 논문(The perceptron, a perceiving and recognizing automaton Project Para.)에서 하나의 뉴론이 정보를 받은 후, 그 정보를 다음 뉴론으로 전달할 것인가 전달하지 않을 것인가를 결정하기 위하여, 자기가 받은 입력 특성$^{features}$에 곱하는 최적의 가중치$^{weights}$를 자동적으로 학습하는 퍼셉트론 알고리즘을 제안하였습니다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/Rosenblatt.png?raw=true\" width=300></img>\n",
    "<center>출처 : https://commons.wikimedia.org/wiki/File:Rosenblatt_21.jpg</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 앞 강의에서 하나의 뉴론 즉 퍼셉트론을 다음과 같이 모델링하였습니다. 그림을 보면 직감적으로 알 수 있듯이 퍼셉트론은 다수의 신호$^{input}$를 입력\n",
    "받아서 하나의 신호$^{output}$를 출력합니다. 그의 구성을 좀 더 자세히 살펴 볼 필요가 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/simple_node_activate.png?raw=true\" width=\"400\">\n",
    "<center>그림 1: 퍼셉트론</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 자료를 나타내는 입력 $\\mathbf{x}$와 가중치 $\\mathbf{w}$는 여러 개의 항목을 표시할 수 있는 m 차원의 벡터이며, 각각의 입력 $x$와 각각의 가중치 $w$의 곱의 합은 뉴론의 순수한 입력에 해당합니다.  임계값(-$\\theta$) 혹은 바이어스를 $w_0 = b$과 $x_0 = 1$로 설정하면, 입력과 가중치는 다음과 같이 벡터로 나타낼 수 있습니다. \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{w} = \\begin{bmatrix}\n",
    "w_0\\\\ w_1\\\\ ...\\\\ w_m\n",
    "\\end{bmatrix}\n",
    "\\ \\ , \\ \\ \\ \\ \n",
    "\\mathbf{x} = \\begin{bmatrix}\n",
    "x_0\\\\ x_1\\\\ ...\\\\ x_m\n",
    "\\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "그러면, $z$ 는 다음과 같습니다. \n",
    "\\begin{equation}\n",
    "z = w_0x_0 + w_1x_1 + ... + w_m x_m = \\sum_{j=0}^{m} x_j w_j = \\mathbf{w^Tx}\n",
    "\\end{equation}\n",
    "\n",
    "그러므로, 단 하나의 인공 뉴론도 다양한 연산 기능을 할 수 있습니다. 이것이 70 여년 전에 제안된 퍼셉트론입니다. 이러한 인공 뉴론을 선형 이진 분류에 이용하려면, 다음과 같은 단위 계단 함수(unit step function)를 활성화 함수로 사용할 수 있습니다. \n",
    "\n",
    "\\begin{equation}\n",
    "  h{(z)} =\\begin{cases}\n",
    "   +1 & \\text{$if \\ z > 0$} \\\\\n",
    "    -1 & \\text{$otherwise.$}\n",
    "  \\end{cases}\n",
    "\\end{equation}  \n",
    "\n",
    "이 활성화 함수의 출력 값에 따라 샘플 들을 +1인 경우와 -1인 경우로 이진 분류를 수행할 수 있게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__JoyTips__: \n",
    "\n",
    "기계학습에서는 선형대수학에서 사용하는 기호나 부호를 자주 사용합니다.  $\\mathbf{w^Tx}$는 두 벡터 혹은 행렬을 내적(dot product, 점곱) 혹은 스칼라곱(scalar product)을 하는 것이며, 결과적으로 실수 스칼라를 얻는 연산입니다.  $\\mathbf{w^T}$의 윗첨자 $\\mathbf{T}$는 전치(transpose)뜻하며, $\\mathbf{w^T}$는 $\\mathbf{w}$를 전치한다는 것입니다. \n",
    "\\begin{equation}\n",
    "z = w_0x_0 + w_1x_1 + ... + w_m x_m = \\sum_{j=0}^{m} x_j w_j = \\mathbf{w^Tx}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전치행렬의 한 예를 들면, \n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}  \n",
    "1 & 2 \\\\\n",
    "3 & 4 \\\\\n",
    "5 & 6 \\\\ \n",
    "\\end{bmatrix}^T =\\ \\begin{bmatrix}\n",
    "1 & 3 & 5\\\\\n",
    "2 & 4 & 6\\\\\n",
    "\\end{bmatrix} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "내적의 한 예를 들면, \n",
    "\\begin{equation} \n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 3 \n",
    "\\end{bmatrix} \\times \n",
    "\\begin{bmatrix}  \n",
    "4\\\\ 5\\\\ 6\\\\\n",
    "\\end{bmatrix} \n",
    "= 1 \\times 4 + 2 \\times 5 + 3 \\times 6 = 32\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "수식만을 놓고 보면 매우 복잡해 보이지만, 실제 파이썬 코드를 살펴보면 매우 짧고 간단합니다.\n",
    "이전 강의에서 배웠던 Numpy를 사용하면 매우 간단합니다.\n",
    "\n",
    "만약, \n",
    "\n",
    "입력의 값 $x_0$, $x_1$, ... , $x_9$ 가 1, 2, ..., 10 이고,\n",
    "\n",
    "가중치 $w_0$, $w_1$, ..., $w_9$ 이 11, 12, ..., 20 일 경우,\n",
    "\n",
    "z는 아래와 같이 계산하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape =  (10,)\n",
      "w shape =  (10,)\n",
      "935\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "w = np.array([11, 12, 13, 14, 15, 16, 17, 18, 19, 20]).T\n",
    "\n",
    "print('x shape = ', np.shape(x))\n",
    "print('w shape = ', np.shape(w))\n",
    "z = np.dot(x, w)\n",
    "print(z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 퍼셉트론 이진 분류기\n",
    "\n",
    "70년 전으로 뒤돌아가 로젠블라트 퍼셉트론 알고리즘으로 입력을 두 가지로 분류하는 문제를 도전해보고자 합니다. 다음 그림은 입력값 $z = w^Tx$ 에 대한 출력은 활성화 함수(여기서는 계단함수)를 통과하면서 출력값이 둘(-1 혹은 1) 중에 하나로 압축이 되어 분류되는 것을 보여줍니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/simplePerceptronClassifier.png?raw=true\" width=\"600\">\n",
    "<center>그림 2: 퍼셉트론과 분류기</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 퍼셉트론 학습 방법\n",
    "\n",
    "퍼셉트론 학습은 임의로 설정된 가중치(weight)에서 시작합니다. 이 임의의 가중치와 학습자료를 퍼셉트론 모형에 입력하여 분류가 잘못 되었을 때 가중치를 개선해 나갑니다. 이러한 방법으로 가중치를 계속 개선하면서 최적의 가중치 값을 얻게 됩니다. 이렇게 여러 자료를 가지고 분류를 해보면서 가중치를 점진적으로 개선해나가므로 우리는 이것을 학습이라고 부릅니다. 퍼셉트론은 모든 학습자료가 정확히 분류될 때까지 학습을 진행하기 때문에 학습자료가 선형적으로 분리될 수 있을 때 적합한 알고리즘입니다.  선형분류는 아래와 같이 직선으로 자료를 분류하는 것입니다. \n",
    "그렇다면 선형분류로 분류하지 못할 경우는 어떻게 될까요? 이 경우에 대해서는 다음 강의에서 자세히 설명하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/perceptronLearning.png?raw=true\" width=\"500\">\n",
    "<center>그림 3: 퍼셉트론 학습 방법(출처:https://en.wikipedia.org/wiki/Perceptron)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그림 3에서와 같이 자료의 개수가 점점 많아짐에 따라 직선의 기울기와 절편을 변화시키면서 자료를 가장 잘 분류할 수 있는 선형 분류기를 찾습니다.\n",
    "이 때, $w_0 = b, x_0 = 1$로 설정하면 $z = w^Tx + b$이 되므로, 직선의 기울기는 $w^T$에 따라 변화하며 절편은 $b$, 즉 바이어스에 따라 변화한다고 설명할 수 있습니다.\n",
    "학습을 반복할 수록 가중치를 개선하기 때문에 선의 기울기가 달라지며, 바이어스의 값을 조정함에 따라 직선의 위치도 변하게 됩니다. 그렇다면, 가중치와 바이어스가 모델 학습에 어떠한 영향을 주게 될까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가중치는 입력 값과 곱해져 출력 값에 영향을 주는 매개변수입니다. 따라서, 주어진 입력에 대해 그 영향도를 조절하여 가중치를 부여함으롤써 출력 값을 계산하는 역할을 합니다.\n",
    "\n",
    "바이어스는 활성화 함수에서 가중치와 입력 값을 곱한 값을 바탕으로 바이어스보다 큰지 작은지 비교하여 뉴런을 활성화 시킬 것인지 활성화 시키지 않을 것인지 결정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 데이터를 바탕으로 가중치와 바이어스를 설정했으면, 학습 데이터가 아닌 새로운 데이터도 현재 퍼샙트론이 잘 분류해내는지 알아보면 됩니다. 만약 만들어진 퍼셉트론이 새로운 데이터를 잘 분류한다면 가중치와 바이어스가 제대로 설정된 것이고, 제대로 분류하지 못한다면, 다시 가중치와 바이어스를 설정해주면 됩니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 퍼셉트론의 과적합$^{overfitting}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "와우 그러면 학습 데이터를 모두 제대로 분류할 수 있을 때까지 가중치와 바이어스를 계속해서 조정하면, 완벽한 퍼셉트론을 만들 수 있겠네요? \n",
    "\n",
    "그러면 참 좋겠지만, 기계학습을 만든 이유를 다시한번 생각해봐야 합니다. 기존에 있는 데이터는 이미 라벨링이 된 데이터이며, 즉, 이미 분류가 완료된 데이터입니다. 우리가 알고 싶은 것은 우리가 만든 퍼셉트론이 라벨링 되지 않은 새로운 데이터도 분류할 수 있는지 여부입니다. \n",
    "\n",
    "학습 데이터를 다 분류할 수 있으면 새로운 데이터도 당연히 분류할 수 있지 않나요? 라고 생각할 수 있지만, 학습 데이터가 정확하게 분류가 되어 있으면 가능합니다만, 경계선 상에 데이터가 많으면 많을 수록, 새로운 데이터를 제대로 분류하지 못하는 경우가 생깁니다. \n",
    "\n",
    "아래 그림을 살펴봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/OverFitting.png?raw=true\" width=350></img>\n",
    "<center>그림 4: 과적합</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파란색 점과 빨간색 점이 각각 개와 고양이를 나타내고, 검은색 선이 퍼셉트론이 어느정도 개와 고양이를 분류하도록 만들어진 경우이고, 완벽히 분류하도록 만든 경우가 초록색 선입니다.\n",
    "\n",
    "현재 학습 데이터는 모두 분류가 되어 완벽한 것 같지만, 만약에 아래와 같이 새로운 개와 고양이의 사진이 들어올 경우 어떻게 될까요?\n",
    "눈에 쉽게 보이기 위해 새로운 개는 보라색 점으로 새로운 고양이는 주황색 점으로 표시했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/OverFitting2.png?raw=true\" width=350></img>\n",
    "<center> 그림 5: 과적합-2</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제가 발생하지요? 새로운 개와 고양이는 기존의 퍼셉트론이 개를 고양이로 고양이를 개로 분류하게 됩니다. 즉, 기존의 학습 데이터를 너무 믿은 나머지 새로운 학습 데이터를 제대로 분류하지 못하는 현상이 발생하게 되는 것입니다. 이를 기계학습에서는 __과적합$^{overfitting}$__  되었다고 말합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기계학습에서는 모델을 학습 할 때,과적합 되지 않도록 학습하는 것을 매우 중요하게 생각합니다. 분류 학습에서 모델이 과적합된다는 것은 학습 과정에서 특정 데이터에 너무 치중되어 학습 데이터(training set)는 잘 분류하지만 새로운 데이터에 적용했을 때에는 제대로 분류하지 못하여 성능이 좋지 않은 것을 의미합니다. 즉, 학습 데이터만을 만족하는 퍼셉트론이 나와버리게 되는 것입니다. 따라서 모델을 학습할 때에 어느 데이터에 적용 하여도 잘 동작하는 분류기를 만드는 것이 중요합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그러나 과적합을 두려워하여 어느 정도 오차를 허용해주기 시작하면, 과적합과는 반대인 __과소적합$^{underfitting}$__이 발생할 수 있습니다. 이렇게 되면, 새로운 데이터, 학습 데이터 모두 제대로 분류하지 못하는 아무런 쓸모 없는 퍼셉트론이 만들어지게 되는 것이지요.\n",
    "\n",
    "따라서, 퍼셉트론을 학습할 때에는, 어느 한 쪽에 치우치지 않도록 자료들을 가장 잘 표현할 수 있는 모델을 만드는 것이 매우 중요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고 자료\n",
    "\n",
    "- 스탠포드 대학 앤드루 응 교수의 기계학습 강의 <p>\n",
    "    - https://www.coursera.org/specializations/deep-learning\n",
    "    - https://www.coursera.org/learn/machine-learning/home/welcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 정리 \n",
    "- 퍼셉트론의 역사\n",
    "- 퍼셉트론의 구조와 학습방법\n",
    "- 퍼셉트론의 이진분류기와 활성화함수 \n",
    "- 과대적합과 과소적합\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
