{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파이썬으로 배우는 기계학습\n",
    "# Machine Learning with Python\n",
    "**************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제 6-1 강: 객체지향 퍼셉트론$^{Object-Oriented \\ Perceptron}$ 구현\n",
    "\n",
    "## 학습목표\n",
    "    - 객체지향 퍼셉트론을 구현한다.\n",
    "    - 객체지향 프로그래밍의 장점을 잘 활용한다. \n",
    "\n",
    "\n",
    "## 학습 내용\n",
    "    - 퍼셉트론 클래스 설계\n",
    "    - 객체지향 퍼셉트론 구현하기\n",
    "    - 객체지향 프로그래밍 기법 활용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 코드셀은 이번 학습에서 필요한 라이브러리를 미리 실행하는 것입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'joy' from 'C:\\\\Users\\\\user\\\\Dropbox\\\\_KMoocML\\\\KMOOC-shared\\\\joy.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import imp\n",
    "import joy\n",
    "imp.reload(joy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 객체지향 퍼셉트론: Object-Oriented Perceptron 구현\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지난 학습에서 객체지향 프로그래밍을 활용하여 객체지향 퍼셉트론 클래스를 구현해보려고 합니다. 앞에서 구현한 `percetron_train()` 함수를 구현한 경험을 살리면, 객체지향 퍼셉트론 클래스를 구현하는 것이 그렇게 어렵지는 않을 것입니다. \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. class Perceptron\n",
    "\n",
    "\n",
    "- `class Perceptron:` <p>\n",
    "\n",
    "    객체지향 퍼셉트론을 만들려고 할 때, 제일 먼저 할 일은 클래스 이름을 정하는 것인데, 여기서는 `Perceptron`이라고 정했습니다. 클래스 이름은 함수들과 구별하기 위하여 자바처럼 대문자를 사용했는데, 자바에서는 클래스 이름을 대문자로 사용하는 것이 필수이지만, 파이썬에서는 개인적으로 선호에 따라 사용하면 됩니다. 가능하면 대문자를 사용하는 것을 권장합니다. 함수를 선언할 때 `def`를 사용한 것처럼, 클래스를 선언할 때 `class`을 사용하고 클래스 이름을 명시합니다. \n",
    "    \n",
    "    또한 클래스 이름을 정의하고 난 직후에, 클래스 사용자를 위한 설명을 하는 것이 관례이며, 이 부분은 3개의 따옴표를 중복한 것으로 시작하고 끝을 맺습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 생성자와 메소드\n",
    "\n",
    "- `def __init__(self, eta=0.1, epochs=10, random_seed=1):`\n",
    "\n",
    "    함수 `perceptron_train()`에서 인자로 전달하는 값들은 자연스럽게 클래스 생성자 `__init__` 메소드에서 인스턴스 변수들의 초기값으로 설정을 합니다. \n",
    "```\n",
    "def perceptron_train(X, y, w=None, X0=False, eta=0.1, epochs=10, random_seed=None):\n",
    "```\n",
    "    이를 통해 메소드를 호출할 때마다, `perceptron_train`에서 사용한 인자들을 전달하는 것이 아닌, 인스턴스 변수들을 이용할 수 있게 됩니다. `X`, `y`, `w`는 객체를 초기화 할 당시에는 알 필요가 없기 때문에 `__init__` 메소드에 전달하지는 않습니다. \n",
    "\n",
    "\n",
    "- `def fit(self, X, y, X0=False):`\n",
    "\n",
    "    훈련자료 `X`와 클래스 레이블 `y`를 인자로 받아 기계학습을 수행하는 함수입니다. `fit()`에서 가중치를 조절하여 클래스 레이블을 예측하고, 어떻게 가중치를 조절할 것인지 판단하기 위하여 `predict()` 메소드를 호출합니다. 함수가 진행되는 동안, 가중치 `w`를 인스턴스 변수로 설정합니다. 이를 통해 가중치 `w`를 클래스 내부 어떤 메소드에서도 사용할 수 있게 만들어줍니다. 함수가 종료될 때 인스턴스 변수가 변화된 자기 자신을 반환함으로써, 함수의 반환 값을 이용하여 다시 객체를 설정할 필요 없이 반환된 객체 그대로 사용할 수 있게 만들어줍니다.\n",
    "    \n",
    "    연산의 편의를 위해 가중치 fit()메소드에서 w를 2차원으로 정의하지 않고, 1차원의 단순한 배열로 정의합니다. 그러나, 후반부에 같은 내용을 가중치 w를 2차원으로 정의할 경우도 다루고 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "- `def net_input(self, X):`\n",
    "\n",
    "    `np.dot(x,y)`는 벡터 `x`, `y`의 내적 또는 행렬 `x`, `y`의 곱을 반환합니다. 따라서 `net_input(self, X)`는 훈련자료 `X`의 각 입력값과 그에 따른 가중치를 곱한 총합, 순입력 함수의 결과값 $\\sum{w_i x_i}$을 구현한 것입니다. \n",
    "   \n",
    "   \n",
    "- `def predict(self, X):`    \n",
    "    \n",
    "   `self.net_input(X)`의 값, 순입력 함수 결과값 `z`가 임계값(0)보다 크면 `maxy` 1, 그렇지 않으면, `miny` -1을 반환하는 메소드입니다. 활성화 함수를 구현한 메소드로  클래스 레이블을 출력하기 위해서도 사용합니다. 경우에 따라, 클래스 레이블이 1과 -1이 아니라 1과 0로 정의되어 있을 경우에는, `mid` 0.5를 임계값으로 사용합니다. 이 코드에서의 활성화 함수는 계단 함수를 사용했습니다. 임계값보다 클 경우, `maxy`을, 작을 경우 `miny`을 반환합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile code/Perceptron.py\n",
    "#%load code/Perceptron.py\n",
    "# # Implementation of Rosenblatt's perceptron algorithm for classification.\n",
    "# Author: Youngsup KIm, idebtor@gmail.com\n",
    "# 2018.03.01 - Creation\n",
    "# 2018.04.18 - works with plot_descision_region(), net_input() modified\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class Perceptron:\n",
    "    \"\"\"\n",
    "    Perceptron classifier: This implementation of the Perceptron expects \n",
    "    binary class labels in {0, 1}.\n",
    "    \n",
    "    Parameters\n",
    "        eta : float (default: 0.1), Learning rate (between 0.0 and 1.0)\n",
    "        epochs : int (default: 10), Number of passes over the training dataset.\n",
    "            Prior to each epoch, the dataset is shuffled to prevent cycles.\n",
    "        random_seed : int, Random state for initializing random weights and shuffling.\n",
    "        \n",
    "        X0: If True, then X must have X_0 = 1 in all samples.\n",
    "                Set it Faslse, if X does not have X_0 \n",
    "    \n",
    "    Attributes\n",
    "        w  : 1d-array, shape={n_features, }, Model weights after fitting. Includes bias\n",
    "        w_ : 2d-array, shape={epochs, n_features}, Weights in every epoch\n",
    "        cost_ : list, Number of misclassifications in every epoch.\n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.1, epochs=10, random_seed=1):\n",
    "        self.eta = eta\n",
    "        self.epochs = epochs\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "    def fit(self, X, y, X0=False):\n",
    "        if X0 == False:\n",
    "            X = np.c_[ np.ones(len(y)), X]   \n",
    "            \n",
    "        np.random.seed(self.random_seed)\n",
    "        self.w = np.random.random(X.shape[1]) \n",
    "    \n",
    "        self.maxy, self.miny = y.max(), y.min()\n",
    "        self.cost_ = []\n",
    "        self.w_ = np.array([self.w])\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            errors = 0\n",
    "            for xi, yi in zip(X, y):\n",
    "                yhat = self.activate(xi)\n",
    "                if yi != yhat:\n",
    "                    delta = self.eta * (yi - yhat) * xi    \n",
    "                    self.w = self.w + delta \n",
    "                    errors += 1\n",
    "            self.cost_.append(errors)\n",
    "            self.w_ = np.vstack([self.w_, self.w])\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):        \n",
    "        if X.shape[0] == self.w.shape[0]:\n",
    "            z = np.dot(self.w.T, X)\n",
    "        else:                       \n",
    "            z = np.dot(X, self.w[1:]) + self.w[0]\n",
    "        return z\n",
    "\n",
    "    def activate(self, X):\n",
    "        mid = (self.maxy + self.miny) / 2\n",
    "        Z = self.net_input(X)\n",
    "        return np.where(Z > mid, self.maxy, self.miny)\n",
    "    \n",
    "    def predict(self, X):     \n",
    "        return self.activate(X)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 정리\n",
    "- 페셉트론 클래스 설계\n",
    "- 퍼셉트론 함수를 객체지향 퍼셉트론으로 전환\n",
    "- OOP프로그래밍 경험하기\n",
    "\n",
    "-------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
