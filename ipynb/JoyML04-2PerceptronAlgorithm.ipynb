{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파이썬으로 배우는 기계학습\n",
    "# Machine Learning with Python\n",
    "**************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 제 4-2 강: 퍼셉트론 알고리즘\n",
    "\n",
    "## 학습 목표\n",
    "    - 퍼셉트론 알고리즘을 이해한다.\n",
    "    \n",
    "## 학습 내용\n",
    "    - 퍼셉트론 알고리즘\n",
    "    - 퍼셉트론 가중치 계산 \n",
    "    - 퍼셉트론 학습 전체 과정\n",
    "    - 퍼셉트론 알고리즘의 한계\n",
    "    - 퍼셉트론 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. [퍼셉트론](https://en.wikipedia.org/wiki/Perceptron) 알고리즘\n",
    "\n",
    "\n",
    "### 1-1. 알고리즘$^{algorihtm}$\n",
    "\n",
    "우리가 구하고자 하는 것은 입력값 $x$들을 분류해 낼 수 있는 가중치 $w$인데, [로젠블라트](https://en.wikipedia.org/wiki/Frank_Rosenblatt)가 처음 제안한 학습 알고리즘은 다음과 같이 요약할 수 있습니다.  \n",
    "1. 가중치를 0 혹은 무작위 작은 수로 초기화 한다. \n",
    "2. 각 학습 자료$^{Training \\ Sample}$  $x^{(i)}$에 대해 다음을 실행한다. \n",
    "   - 출력 $\\hat{y}$를 계산한다.    즉 $\\hat{y} = h(\\mathbf{w^Tx})$\n",
    "   - 가중치$w_j$를 조정한다. 즉 $w_j := w_j + \\Delta w_j$\n",
    "   \n",
    "$x^{(i)}$ 에서 윗첨자 $(i)$는 입력되는 여러 학습자료에 하나씩 번호를 붙인 것입니다. 따라서 학습자료는 각각 $x^{(1)}, x^{(2)}$, ...이 됩니다.  $\\hat{y}$ 는 y hat(햇)으로 읽으며, 퍼셉트론이 계산한, 즉 퍼셉트론이 예측한$^{predicted}$ 예측값입니다.  $y$는 실제값 혹은 클래스 레이블(True Class Label)이라고 하며, 명시적인 정답을 말합니다. 실제값 혹은 클래스 레이블은 입력된 해당 학습자료가 출력해야 할 이미 알려진 참 값을 말합니다. $\\Delta$는 delta$^{델타}$라고 읽으며, 수학에서 \"차이\" 혹은 \"작은 값\"을 표시할 때 흔히 사용합니다. 기호 $:=$는 등호(=)가 아니며, 오른쪽 항을 계산하여 왼쪽 항에 설정(Assignment)한다는 개념입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. 가중치 계산\n",
    "\n",
    "각 학습자료에 따라 계산을 하면서, 가중치를 조정하는 값은 다음의 방법을 따릅니다.  \n",
    "\n",
    "\\begin{align}\n",
    "   \\Delta w_j= \\eta (y^{(i)} - \\hat{y}^{(i)})x_j^{(i)}   \\tag{1} \n",
    "\\end{align}\n",
    "   \n",
    "여기서 $\\eta^{에타}$는 학습률은 나타내며 대개 0부터 1.0 사이의 상수입니다. 식(1)을 2차원의 예를 들어 각각의 경우를 풀어서 표기하면 다음과 같습니다. 여기서 주의할 것은 가중치를 조정할 때, 모든 값($w_0$, $w_1$, ..., $w_n$)을 동시에 조정해야 한다는 것입니다. \n",
    "\n",
    "\\begin{align}\n",
    "   \\Delta w_0 &= \\eta (y^{(i)} - \\hat{y}^{(i)})   \\\\\n",
    "   \\Delta w_1 &= \\eta (y^{(i)} - \\hat{y}^{(i)})x_1^{(i)}  \\\\   \n",
    "   \\Delta w_2 &= \\eta (y^{(i)} - \\hat{y}^{(i)})x_2^{(i)}   \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리가 퍼셉트론 예제를 다루기 전에 식(1)의 의미를 살펴보면 좋겠습니다. 식(1)을 관찰해보면, 예측값과 실제값(클래스 레이블)의 차이에 입력과 학습률을 곱한 값만큼 가중치를 조정하는 것입니다. 이것이 퍼셉트론 학습원칙의 핵심입니다. \n",
    "\n",
    "이 원칙이 어떻게 지켜지는지 간단한 테스트를 해봅시다. 활성화 함수 $h$가 양극성 계단 함수로, 1또는 -1만 반환한다고 해봅시다.\n",
    "\n",
    "\n",
    "실제값 y와 예측값 $\\hat{y}$이 같은 경우(다 같이1 혹은 다 같이 -1)를 식(1)에 대입하면, $\\Delta{w_j}$는 0가 되므로, $w_j$는 조정되지 않습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "   \\Delta w_j &= \\eta (1^{(i)} - 1^{(i)})x_j^{(i)} = 0  \\\\\n",
    "   \\Delta w_j &= \\eta (-1^{(i)} - (-1^{(i)}))x_j^{(i)} = 0 \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "반면에, 클래스 레이블(참값) y와  예측한 값 $\\hat{y}$이 서로 다를 경우(하나는 1, 다른 하나는 -1)를 식(1)에 대입하면, $\\Delta{w_j}$는 0이 아니므로, $w_j$는 다음과 같이 커지거나 작아지도록 조정이 될 것입니다.  \n",
    " \n",
    " \\begin{align}\n",
    "   \\Delta w_j &= \\eta (1^{(i)} - (-1^{(i)}))x_j^{(i)} = \\eta (2)x_j^{(i)} \\\\\n",
    "   \\Delta w_j &= \\eta (-1^{(i)} - 1^{(i)})x_j^{(i)} = \\eta (-2)x_j^{(i)} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__예제 1__: 학습을 통해 다음의 가중치 $w$ 가 학습되었고, 예측값 $\\hat{y}$와 클래스 레이블(참값) $y$ 가 주어졌다고 가정합시다. 몇 번째 샘플의 가중치가 조정될까요?\n",
    "\n",
    "- $\\mathbf{\\hat{y}} = (\\hat{y_1}, \\hat{y_2}, \\hat{y_3}, \\hat{y_4}, \\hat{y_5}) = (1, -1, 1, 1, -1)$ \n",
    "- $\\mathbf{y} = ({y_1}, {y_2}, {y_3}, {y_4}, {y_5}) = (1, -1, -1, 1, -1)$ \n",
    "- $(x_1, x_2) = (0, 1)$\n",
    "\n",
    "(1) 1\n",
    "(2) 2\n",
    "(3) 3\n",
    "(4) 4\n",
    "(5) 5\n",
    "\n",
    "__예제풀이__: (3)\n",
    "\\begin{align}   \n",
    "    {y_1} - \\hat{y_1} = 0\\\\\n",
    "    {y_2} - \\hat{y_2} = 0\\\\\n",
    "    {y_3} - \\hat{y_3} = 2\\\\\n",
    "    {y_4} - \\hat{y_4} = 0\\\\\n",
    "    {y_5} - \\hat{y_5} = 0\\\\\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지 설명한 퍼셉트론 알고리즘을 도식화하면 다음과 같이 요약할 수 있습니다. \n",
    "\n",
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/PerceptronAlgorithm.png?raw=true\" width=\"600\">\n",
    "<center>그림 3: 퍼셉트론 알고리즘</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 퍼셉트론 전체 학습 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "퍼셉트론이 만들어지기 까지의 전체 과정을 요약하면 다음과 같습니다.\n",
    "1. 학습 자료들을 입력받는다.\n",
    "2. 각각이 학습 자료 안에 있는 데이터($x$)를 초기 가중치($w$)와 곱한 값($z$)을 구한다.\n",
    "3. 2에서 구한 값을 활성화 함수(예를 들어 양극성 계단 함수)에 넣어 예측 값($\\hat{y}$)를 구한다.\n",
    "4. 예측값과 실제값을 비교하여 새로운 가중치 값($\\Delta{w}$)을 만든다.\n",
    "5. 새로운 가중치 값($w$=$w$+$\\Delta{w}$)과 다음 학습 자료 안에 있는 데이터를 곱한 값($z$)을 구한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/Perceptron-process.png?raw=true\" width=800></img>\n",
    "<center>그림 4: 퍼셉트론 알고리즘의 전체 과정</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "퍼셉트론이 비록 70년 이상된 알고리즘이나,두 클래스가 선형으로 분류 가능하다면  이 알고리즘은 하나의 퍼셉트론으로도 가중치를 찾을 수 있도록 멋지게 수렴합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 퍼셉트론 알고리즘의 한계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. 배타적논리합$^{XOR}$\n",
    "1957년 코넬 항공 연구소의 프랭크 로젠블랏트가 퍼셉트론 알고리즘을 발표하고 실제로 실행하는 컴퓨터(기계?)를 제작했을때, 뉴욕타임즈는 가까운 미래에 말하고, 생각하고, 걸을 수 있는 컴퓨터의 세상이 도래할 것이라는 미래 예측 기사를 냈습니다.  그러나 1969년, 퍼셉트론으로는 배타적논리합$^{XOR}$ 문제도 풀 수 없다는 사실을 MIT 미디어 랩의 창시자이며, 인공지능의 아버지라고 불리는 마빈 민스키$^{Marvin \\ Minsky}$교수가 증명하였습니다.  다만, 다층 퍼셉트론(MLP: Multi-Layer Perceptron)을 학습시킬 수 있다면, XOR문제를 풀 수 있지만, 그 방법이 없다고 했습니다.  그런데, 1974년, 당시 하버드 대학의 박사과정 학생이었던 펄 워보스가 최초로 MLP를 학습시킬 수 있는 오류 역전파(Backpropagation)을 발표하면서, 기계학습은 새로운 전기를 맞게 되었습니다.  이 알고리즘에 대해서 우리도 곧 다룰 것입니다. 기대하십시오. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "배타적논리합의 경우, 두 입력값이 같으면 0이며 두 입력값이 다를 경우 1을 반환해야 합니다. 두 입력값의 경우를 그래프로 나타내보면 아래 왼쪽 그림과 같이 나타납니다. 그러나 해당 그래프는 선형적으로 분류될 수 없음을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/XORClassifier3.png?raw=true\" width=\"600\"></img>\n",
    "<center>그림 5: 퍼셉트론 알고리즘의 한계 (베타적논리합)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "퍼셉트론 알고리즘을 실행할 때, 입력되는 학습자료가 선형으로 분류 가능하지 않을 수 있으므로, 오차의 한계를 설정하거나 학습의 최대 반복 횟수(에포크$^{epoch}$)를 미리 정하는 것이 좋습니다. 그렇지 않다면 퍼셉트론 알고리즘은 영원히 반복되며, 가중치를 이상한 방향으로 학습해 나갈 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. 최적화된 가중치\n",
    "\n",
    "또 한가지 퍼셉트론의 한계는 아래 왼쪽 그림과 같이 두 클래스를 분류한다고 할 때 퍼셉트론 알고리즘은 두 직선에 사이 존재하는 하나의 직선으로 수렴하지만, 두 직선 사이에 존재하는 최적의 직선을 선택할 수는 없습니다. 오른쪽 그림과 같이 하나의 새로운 값이 들어온다고 했을 때, 이 입력 값을 분류하기 위해서는 또 새로운 직선이 만들어지기 때문이지요. 따라서 어떠한 직선이 모든 입력을 구분하는 최적의 직선이라고 퍼셉트론은 말할 수 없습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/Limit_Perceptron.png?raw=true\" width=\"800\">\n",
    "<center>그림 3: 퍼셉트론 분류기의 한계</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "퍼셉트론을 계속 학습하여, 가중치를 변화시키더라도, 어떤 가중치 값들이 가장 이상적으로 모든 값(학습 데이터와 새로운 데이터)들을 분류해는지 알 수 없습니다. 실제 새로운 데이터를 넣어보기 전까지는 퍼셉트론은 학습된 데이터에 한해, 분류를 할 수 있다 없다만 알려줄 뿐입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 퍼셉트론 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 위에서 배운 퍼셉트론을 갖고 실제로 퍼셉트론을 만들고 학습 자료를 구분해보도록 합시다.\n",
    "\n",
    "그림 4-1과 같이 6개의 학습(훈련) 자료가 주어졌다고 가정합시다.  각 자료의 클래스 레이블은 `y = [1, -1, -1, -1, 1, 1]`입니다. 학습 자료들을 사용하여 이진 페셉트론을 학습시키고, 학습 자료들을 이진 분류할 수 있는 가중치를 구하고, 그림 4-2와 같이 시각화하는 것이 목표입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "    <td><img src='https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/perceptronExample1.png?raw=true' width=\"400\"> \n",
    "        <center> 그림 4-1: 퍼셉트론 예제 1</center> </td>\n",
    "    <td><img src='https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/perceptronExample1Result_7.png?raw=true' width=\"400\"> \n",
    "        <center> 그림 4-2: 퍼셉트론 예제 1 결과($\\eta=0.1$)</center></td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "\n",
    "이진 퍼셉트론의 가중치$\\mathbf{w}$를 구하는 계산을 직접 손으로 계산하면서 아래 표를 완성해 봅시다. 단, 초기 가중치는 계산의 편의를 위하여 $\\mathbf{w^T} = [0 \\ \\ 1 \\ \\ 0.5]$으로 설정합니다.  학습률은 $\\eta = 0.1$, 학습자료는 1번 즉 $\\mathbf{x}^{(1)}= [1, 1]$부터 차례로 입력합니다. \n",
    "\n",
    "표에 나온 값은 $\\mathbf{x}^{(1)}= [1, 1]$에 bias 까지 추가한 상태입니다. 즉, bias를 b로 나타내지 않고 $w_0$$x_0$으로 나타낸 것입니다. 위에서 가중치 백터의 첫번 째 값이 0이므로 $w_0$를 0으로, $x_0$를 1로 둔 것으로 생각하면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                      표 1: 각 학습 자료의 입력에 따른 가중치 계산 과정 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| $i$   |$x_0^{(i)},x_1^{(i)},x_2^{(i)}$ |  $w_0, w_1, w_2$| $\\mathbf{w^Tx}$ | $\\hat{y}^{(i)}$| $y^{(i)}$ |$\\eta$ |$\\Delta w$ |\n",
    "| ----  |    ------         |  --  |:---------------:|:----------------:|:----------:|:------------:|:-----------:|\n",
    "|  1    |  (1.0, 1.0, 1.0)  |(0.0, 1.0, 0.5) | $\\hspace{60pt}$ |  $\\hspace{30pt}$ |     1        |  0.1    | $\\hspace{60pt}$ \n",
    "|  2    |  (1.0, 2.0, -2.0) |$\\hspace{60pt}$ | $\\hspace{60pt}$ |$\\hspace{60pt}$   |    -1        |  0.1   |$\\hspace{60pt}$ \n",
    "|  3    |  (1.0, -1.0,-1.5) |$\\hspace{60pt}$ | $\\hspace{60pt}$ |$\\hspace{60pt}$   |    -1        |  0.1   |$\\hspace{60pt}$ \n",
    "|  4    |  (1.0, -2.0, -1.0)|$\\hspace{60pt}$ | $\\hspace{60pt}$ |$\\hspace{60pt}$   |    -1        |  0.1   |$\\hspace{60pt}$ \n",
    "|  5    |  (1.0, -2.0, 1.0) |$\\hspace{60pt}$ | $\\hspace{60pt}$ |$\\hspace{60pt}$   |     1        |  0.1   |$\\hspace{60pt}$ \n",
    "|  6    |  (1.0, 1.5, -0.5) |$\\hspace{60pt}$ | $\\hspace{60pt}$ |$\\hspace{60pt}$   |     1        |  0.1   |$\\hspace{60pt}$ \n",
    "| final |     -             | $\\hspace{60pt}$ |       -         |        -        |     -        |    -    |      -        |       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째로 $i$가 1일 경우, $\\Delta w$의 값을 구해보도록 합시다.\n",
    "\n",
    "$x^{(1)}$ = (1.0, 1.0, 1.0) 이고, $w^{T}$값은 (0.0, 1.0, 0.5)이므로 두 벡터의 내적 값 $\\mathbf{w^Tx}$ 은 (1.0 $\\times$ 0.0) + (1.0 $\\times$ 1.0) + (1.0 $\\times$ 0.5) = 1.5가 됩니다.\n",
    "\n",
    "활성화 함수가 양극성 계단 함수라고 할 때, 1.5는 1로 변환됩니다. 따라서  $\\hat{y}^{(1)}$의 값은 1이 됩니다. \n",
    "기댓값 $\\hat{y}^{(1)}$과 실제값 $y$의 값이 같기 때문에 $\\Delta w$ = 0.1$\\times$(1 - 1) = 0 이 됩니다. \n",
    "\n",
    "첫 번째 입력 값은 가중치를 변화시키지 못했습니다. 이때 착각해서는 안되는 점은, 가중치가 변하지 않았다고 하여, 해당 입력 값이 쓸모 없는 것은 절대로 아닙니다. 가중치가 변하지 않았다는 것은 현재 가중치로 입력 값을 잘 분류할 수 있다는 뜻을 입증하는 근거가 되기 때문이지요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "퍼셉트론이 첫 번째 학습한 후, 표에 채워지는 내용은 다음과 같습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                      표 1-1: 각 학습 자료의 입력에 따른 가중치 계산 과정 \n",
    "\n",
    "| $i$   |  $x^{(i)}$       |  $ w $           | $\\mathbf{w^Tx}$ | $\\hat{y}^{(i)}$  | $y^{(i)}$ |  $\\eta$ |$\\Delta w$ |\n",
    "|:------:|:-----------------:|:--------------:|:---------------:|:----------------:|:----------:|:--------:|:-----------:|\n",
    "|  1     |  (1.0, 1.0, 1.0)  |(0.0, 1.0, 0.5) | 1.5             |           1 |     1        |  0.1    | (0.0, 0.0, 0.0)\n",
    "|  2     |  (1.0, 2.0, -2.0) |                 |                 |                 |    -1        |  0.1   |$\\hspace{60pt}$ \n",
    "|  3     |  (1.0, -1.0,-1.5) |                 |                 |                 |    -1        |  0.1   |$\\hspace{60pt}$ \n",
    "|  4     |  (1.0, -2.0, -1.0)|                 |                 |                 |    -1        |  0.1   |$\\hspace{60pt}$ \n",
    "|  5     |  (1.0, -2.0, 1.0) |                 |                 |                 |     1        |  0.1   |$\\hspace{60pt}$ \n",
    "|  6     |  (1.0, 1.5, -0.5) |                 |                 |                 |     1        |  0.1   |$\\hspace{60pt}$ \n",
    "| final  |     -             | $\\hspace{60pt}$ |       -         |      ----        |     -        |    -    |      -        |       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 번째로 $i$가 2일 경우, $\\Delta w$의 값을 구해보도록 합시다.\n",
    "\n",
    "$x^{(2)}$ = (1.0, 2.0, -2.0) 이고, $w^{T}$값은 첫 번째 경우에서 변하지 않았기 때문에 (0.0, 1.0, 0.5)입니다. 두 벡터의 내적 값 $\\mathbf{w^Tx}$ 은 (1.0 $\\times$ 0.0) + (2.0 $\\times$ 1.0) + (-2.0 $\\times$ 0.5) = 1가 됩니다.\n",
    "\n",
    "활성화 함수가 양극성 계단 함수라고 할 때, 1은 1로 변환됩니다. 따라서  $\\hat{y}^{(1)}$의 값은 1이 됩니다. \n",
    "기댓값 $\\hat{y}^{(1)}$과 실제값 $y$의 값과 다르기 때문에 $\\Delta w$ = 0.1$\\times$(-1 - 1) = -0.2 이 됩니다. \n",
    "\n",
    "이제 가중치 값을 변화시킬 차례입니다. \n",
    "\n",
    "\\begin{align}\n",
    "   \\Delta w_j= \\eta (y^{(i)} - \\hat{y}^{(i)})x_j^{(i)}   \\tag{1} \n",
    "\\end{align}\n",
    "\n",
    "이기 때문에, $x^{(2)}$의 원소들의 값에 -0.2를 곱하면 (-0.2, -0.4, 0.4)가 됩니다.\n",
    "\n",
    "퍼셉트론이 두 번째 학습한 후, 표에 채워지는 내용은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                      표 1-1: 각 학습 자료의 입력에 따른 가중치 계산 과정 \n",
    "\n",
    "| $i$    |  $x^{(i)}$       |  $ w $         | $\\mathbf{w^Tx}$ | $\\hat{y}^{(i)}$ | $y^{(i)}$ |  $\\eta$ |$\\Delta w$ |\n",
    "|:------:|:----------------:|:--------------:|:---------------:|:---------------:|:----------:|:--------:|:-----------:|\n",
    "|  1     | (1.0, 1.0, 1.0)  |(0.0, 1.0, 0.5) | 1.5             |           1     |     1      |  0.1    | (0.0, 0.0, 0.0)\n",
    "|  2     | (1.0, 2.0, -2.0) |$\\hspace{60pt}$ | $\\hspace{60pt}$ |$\\hspace{60pt}$  |    -1      |  0.1   |$\\hspace{60pt}$ \n",
    "|  3     | (1.0, -1.0,-1.5) |$\\hspace{60pt}$ | $\\hspace{60pt}$ |$\\hspace{60pt}$  |    -1      |  0.1   |$\\hspace{60pt}$ \n",
    "|  4     | (1.0, -2.0, -1.0)|$\\hspace{60pt}$ | $\\hspace{60pt}$ |$\\hspace{60pt}$  |    -1      |  0.1   |$\\hspace{60pt}$ \n",
    "|  5     | (1.0, -2.0, 1.0) |$\\hspace{60pt}$ | $\\hspace{60pt}$ |$\\hspace{60pt}$  |     1      |  0.1   |$\\hspace{60pt}$ \n",
    "|  6     | (1.0, 1.5, -0.5) |$\\hspace{60pt}$ | $\\hspace{60pt}$ |$\\hspace{60pt}$  |     1      |  0.1   |$\\hspace{60pt}$ \n",
    "| final  |    -             | $\\hspace{60pt}$|       -         |        -        |     -      |    -    |      -        |      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여섯 번째까지 학습한 후에 표에 채워지는 내용은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| $i$   |  $x^{(i)}$       |  $ w $            | $\\mathbf{w^Tx}$ | $\\hat{y}^{(i)}$  | $y^{(i)}$ | $\\eta$ | $\\Delta w$\n",
    "|:------:|:-----------------:|:---------------:|:---------------:|:----------------:|:----------:|:--------:|:-------------:|\n",
    "|  1     |  (1.0, 1.0, 1.0)  | (0.0, 1.0, 0.5)  |  1.5            |        1         |     1        |   0.1   |     0\n",
    "|  2     |  (1.0, 2.0, -2.0) | (0.0, 1.0, 0.5)  |  1.0            |        1         |    -1        |   0.1  | (-0.2,-0.4,0.4) \n",
    "|  3     |  (1.0, -1.0,-1.5) |(-0.2, 0.6, 0.9)  |   -2.15         |       -1         |    -1        |   0.1  |   0\n",
    "|  4     |  (1.0, -2.0, -1.0)|(-0.2, 0.6, 0.9)  |   -2.3          |       -1          |    -1        |  0.1  |   0\n",
    "|  5     |  (1.0, -2.0, 1.0) |(-0.2, 0.6, 0.9)  |   -0.5          |       -1          |     1        | 0.1   | (0.2, -0.4, 0.2)\n",
    "|  6     |  (1.0, 1.5, -0.5) | (0.0, 0.2, 1.1)  |   -0.25         |       -1          |     1        | 0.1   | (0.2, 0.3, -0.1)   \n",
    "| final  |     -             | (0.2, 0.5, 1.0) |  $\\hspace{60pt}$ |       -         |        -        |   -    |     $\\hspace{60pt}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "\n",
    "여기서는 우리가 Step 1에서 산출한 가중치을 다음 공식에 대입하여 판별식을 $x_2$에 관한 식으로 구합니다. 가중치로부터 학습 자료들을 두 클래스로 나누는 판별식$^{decision \\ boundary}$은 $\\mathbf{w^Tx} = 0$입니다.  우리가 산출한 가중치 `w = [0.2, 0.5, 1.0]` 입니다. 그러므로, \n",
    "\n",
    "\\begin{align}\n",
    "  \\mathbf{w^Tx} &= 0  \\\\\n",
    "\\begin{bmatrix}\n",
    "w_0&w_1&w_2\\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "1 \\\\ x_1 \\\\ x_2\n",
    "\\end{bmatrix} &= 0 \\\\\n",
    "  w_0 + w_1x_1 + w_2x_2 &= 0  \\\\\n",
    "  0.2 + 0.5x_1 + 1.0x_2 &= 0  \\\\\n",
    "  x_2 &= -0.5x_1 - 0.2\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "\n",
    "우리가 Step 1에서 산출한 가중치(0.2, 0.5, 1.0)로 `plot_xyw()` 함수를 호출하여 판별식을 학습 자료와 함께 시각화합니다. \n",
    "\n",
    "`plot_xyw()` 함수에서 요구하는 X는 학습(훈련) 자료들이며, y는 각 학습 자료의 클래스 레이블입니다. `W`는 선택적 인자이며, 학습 자료를 이진 분류할 수 있는 가중치 즉 판별식입니다. `annotate`는 각 학습 자료들 일련 번호 표시 여부를 말합니다. 그림을 저장하길 원한다면 `savefig`에 파일 이름을 설정할 수 있습니다.  `plot_xyw()` 함수의 코드에 대한 설명은 다음 강의에서 하도록 하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  \n",
    "%matplotlib inline\n",
    "%run code/plot_xyw.py\n",
    "\n",
    "x = np.array([[1.0, 1.0], [2.0, -2.0], [-1.0, -1.5], [-2.0, -1.0], [-2.0,1.0], [1.5, -0.5]]) \n",
    "X = np.c_[ np.ones(len(x)), x ]\n",
    "y = np.array([1, -1, -1, -1, 1, 1])\n",
    "w = np.array([0.2, 0.5, 1.0])\n",
    "plot_xyw(X, y, w, X0=True, annotate=True, savefig='images/perceptronExample1Step1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드를 한 줄 씩 설명하자면, \n",
    "- `x = np.array([[1.0, 1.0], [2.0, -2.0], [-1.0,-1.5], [-2.0, -1.0], [-2.0,1.0], [1.5, -0.5]]) ` : bias를 뺀 x값을 배열로 나타낸 코드입니다.\n",
    "- `X = np.c_[ np.ones(len(x)), x ]` : bias값으로 1.0을 넣어주는 코드입니다.\n",
    "- `y = np.array([1, -1, -1, -1, 1, 1])` : 각 데이터들의 라벨을 결정해주는 코드입니다.\n",
    "- `w = np.array([0.2, 0.5, 1.0])` : 위에서 최종적으로 구한 가중치 값의 배열을 만드는 코드입니다.\n",
    "- `plot_xyw(X, y, w, X0=True, annotate=True, savefig='images/perceptronExample1Result.png')` : 위에서 나온 데이터들을 시각화 하기 위한 함수를 부르는 코드입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저희가 구한 마지막 가중치 값이 확실하게 입력 데이터을 분류하는 것을 그래프로 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추가로, 위에서 보여드린 `plot_xyw` 함수를 사용해서 각 단계마다 가중치의 변화, 즉 결정 경계가 어떻게 변화하는지 그려보았습니다. 다음 반복 횟수가 많아지면 많아질 수록, 가중치(w)값의 변화와 더불어 입력 값을 더 정확하게 분류하는 것을 아래의 표시된 4 개의 그래프로 확인할 수 있습니다.\n",
    "\n",
    "결론적으로, 이렇게 간단한 알고리즘으로 6개의 입력값을 완벽하게 분류하는 경계선을 찾아냈습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) | (2) | (3) | (4)\n",
    "- | - \n",
    "![alt](https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/perceptronExample1Result_1.png?raw=true) | ![alt](https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/perceptronExample1Result_3.png?raw=true) | ![alt](https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/perceptronExample1Result_6.png?raw=true) | ![alt](https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/perceptronExample1Result_7.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chekcing it by code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 z=1.5, \t y:1, yhat:1, delta[0. 0. 0.], w:[0.  1.  0.5]\n",
      "2 z=1.0, \t y:-1, yhat:1, delta[-0.2 -0.4  0.4], w:[-0.2  0.6  0.9]\n",
      "3 z=-2.15, \t y:-1, yhat:-1, delta[ 0. -0. -0.], w:[-0.2  0.6  0.9]\n",
      "4 z=-2.3, \t y:-1, yhat:-1, delta[ 0. -0. -0.], w:[-0.2  0.6  0.9]\n",
      "5 z=-0.5, \t y:1, yhat:-1, delta[ 0.2 -0.4  0.2], w:[0.  0.2 1.1]\n",
      "6 z=-0.25, \t y:1, yhat:-1, delta[ 0.2  0.3 -0.1], w:[0.2 0.5 1. ]\n",
      "w =  [0.2 0.5 1. ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  \n",
    "%matplotlib inline\n",
    "%run code/plot_xyw.py\n",
    "\n",
    "x = np.array([[1.0, 1.0], [2.0, -2.0], [-1.0, -1.5], [-2.0, -1.0], [-2.0,1.0], [1.5, -0.5]]) \n",
    "X = np.c_[ np.ones(len(x)), x ]\n",
    "y = np.array([1, -1, -1, -1, 1, 1])\n",
    "w = np.array([0.0, 1.0, 0.5])\n",
    "\n",
    "eta = 0.1\n",
    "for i, (xi, yi) in enumerate(zip(X, y)):\n",
    "    z = np.dot(xi, w)                              # Compute net input, same as np.dot(w.T, x)\n",
    "    yhat = np.where(z >= 0.0, 1, -1)          # Apply step func and get output\n",
    "    delta = eta * (yi - yhat) * xi                 # Compute delta    \n",
    "    w += delta                                     # Adjust weight\n",
    "    print('{} z={}, \\t y:{}, yhat:{}, delta{}, w:{}'\n",
    "          .format(i+1, np.round(z,2), yi, yhat, delta, w))\n",
    "\n",
    "print('w = ', w)\n",
    "plot_xyw(X, y, w, X0=True, annotate=True, savefig='images/perceptronExample1Step1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 정리\n",
    "- 퍼셉트론 알고리즘\n",
    "- 퍼셉트론 가중치 계산\n",
    "- 퍼섭트론 학습 전체 과정\n",
    "- 퍼셉트론 알고리즘의 한계\n",
    "- 퍼셉트론 예제\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
